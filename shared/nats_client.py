import asyncio
import json
import logging
from datetime import datetime
from typing import Dict, Any, Optional, Callable
import nats
from nats.js import JetStreamContext
import uuid # Added
import traceback # Added
from shared.message_types import CriticalErrorEvent # Added

logger = logging.getLogger(__name__)

class NATSClient:
    def __init__(self, url: str, agent_id: str):
        self.url = url
        self.agent_id = agent_id
        self.nc: Optional[nats.NATS] = None
        self.js: Optional[JetStreamContext] = None
        self.subscriptions = {}

    async def connect(self):
        """Connect to NATS server"""
        self.nc = await nats.connect(self.url)
        self.js = self.nc.jetstream()

        # Create streams if they don't exist
        await self._setup_streams()

        # Start heartbeat
        asyncio.create_task(self._heartbeat())

        logger.info(f"Agent {self.agent_id} connected to NATS")

    async def _setup_streams(self):
        """Set up JetStream streams"""
        streams = [
            {
                "name": "AI_EVENTS",
                "subjects": ["ai.events.>"],
                "retention": "limits",
                "max_age": 24 * 60 * 60 * 1000000000  # 24 hours in nanoseconds
            },
            {
                "name": "AI_WORKFLOWS",
                "subjects": ["ai.workflows.>"],
                "retention": "workqueue"
            },
            {
                "name": "AI_METRICS",
                "subjects": ["ai.metrics.>"],
                "retention": "limits",
                "max_age": 7 * 24 * 60 * 60 * 1000000000  # 7 days
            },
            {
                "name": "AI_CRITICAL_ERRORS",
                "subjects": ["ai.critical_errors.>"],
                "retention": "limits",
                "max_age": 7 * 24 * 60 * 60 * 1000000000,  # 7 days
                "storage": "file"
            }
        ]

        for stream_config in streams:
            try:
                await self.js.add_stream(**stream_config)
                logger.info(f"Created stream: {stream_config['name']}")
            except Exception as e:
                # Check if it's the specific "stream name already in use" error, which might not be critical
                if "stream name already in use" not in str(e).lower() and "wrong last sequence" not in str(e).lower() : # Added another common non-critical error
                    full_error_message = f"Failed to create or update stream {stream_config['name']}: {e}"
                    logger.error(full_error_message) # Keep local log
                    # Publish this as a critical error originating from the NATSClient itself
                    asyncio.create_task(self.publish_critical_error(service_name=self.agent_id, error_message=full_error_message, severity="CRITICAL", stack_trace=traceback.format_exc()))
                else:
                    logger.info(f"Stream {stream_config['name']} already exists or has sequence mismatch, not treating as new critical error: {e}") # Log as info if expected

    async def _heartbeat(self):
        """Send periodic heartbeat"""
        while True:
            try:
                await self.publish(f"ai.heartbeat.{self.agent_id}", {
                    "agent_id": self.agent_id,
                    "timestamp": datetime.utcnow().isoformat(),
                    "status": "active"
                })
                await asyncio.sleep(30)
            except Exception as e:
                full_error_message = f"Heartbeat failed for agent {self.agent_id}: {e}"
                logger.error(full_error_message) # Keep local log
                asyncio.create_task(self.publish_critical_error(service_name=self.agent_id, error_message=full_error_message, severity="ERROR", stack_trace=traceback.format_exc()))
                await asyncio.sleep(5)

    async def publish_critical_error(self, service_name: str, error_message: str, stack_trace: Optional[str] = None, severity: str = "ERROR"):
        if not self.js:
            # Log locally if JetStream is unavailable, but don't try to publish this specific error to NATS
            logger.error(f"[CRITICAL_ERROR_PUBLISH_FAIL] JetStream not available. Original error for {service_name}: {error_message[:200]}")
            return

        # Create the error event object
        # event_id will be handled by the dataclass default factory
        event = CriticalErrorEvent(
            timestamp=datetime.utcnow().isoformat(),
            service_name=service_name,
            error_message=error_message,
            stack_trace=stack_trace,
            severity=severity
            # event_id is generated by default in CriticalErrorEvent
        )

        try:
            # Serialize the dataclass to a dictionary, then to JSON string
            error_data_dict = event.__dict__
            error_data_json = json.dumps(error_data_dict).encode('utf-8')

            # Define the subject for publishing critical errors
            publish_subject = f"ai.critical_errors.{service_name}"

            await self.js.publish(publish_subject, error_data_json)
            logger.info(f"Successfully published critical error for {service_name} to {publish_subject}: {error_message[:100]}")
        except Exception as e:
            # Log locally if publishing the critical error itself fails
            logger.error(f"[CRITICAL_ERROR_PUBLISH_FAIL] Failed to publish critical error for {service_name}. Error: {e}. Original error: {error_message[:200]}")

    async def publish(self, subject: str, data: Dict[str, Any]):
        """Publish message to NATS"""
        if not self.nc:
            raise RuntimeError("Not connected to NATS")

        message = json.dumps(data).encode()
        await self.nc.publish(subject, message)
        logger.debug(f"Published to {subject}: {data}")

    async def request(self, subject: str, data: Dict[str, Any], timeout: int = 5) -> Dict[str, Any]:
        """Send request and wait for reply"""
        if not self.nc:
            raise RuntimeError("Not connected to NATS")

        message = json.dumps(data).encode()
        response = await self.nc.request(subject, message, timeout=timeout)
        return json.loads(response.data.decode())

    async def subscribe(self, subject: str, callback: Callable):
        """Subscribe to subject"""
        if not self.nc:
            raise RuntimeError("Not connected to NATS")

        async def message_handler(msg):
            try:
                data = json.loads(msg.data.decode())
                await callback(msg.subject, data, msg)
            except Exception as e:
                full_error_message = f"Error handling message on {msg.subject} for agent {self.agent_id}: {e}" # Added msg.subject for context
                logger.error(full_error_message) # Keep local log
                asyncio.create_task(self.publish_critical_error(service_name=self.agent_id, error_message=full_error_message, stack_trace=traceback.format_exc(), severity="ERROR"))

        sub = await self.nc.subscribe(subject, cb=message_handler)
        self.subscriptions[subject] = sub
        logger.info(f"Subscribed to {subject}")

    async def close(self):
        """Close NATS connection"""
        if self.nc:
            await self.nc.close()
            logger.info(f"Agent {self.agent_id} disconnected from NATS")
